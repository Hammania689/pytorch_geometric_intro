{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling of Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just getting my feet wet with graphs\n",
    "from torch_geometric.data import Data\n",
    "from torch import tensor\n",
    "import torch\n",
    "\n",
    "edge_index = tensor([[0, 1, 1, 2],\n",
    "                     [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "print(data)\n",
    "\n",
    "\n",
    "print(f'Keys: {data.keys}')\n",
    "print(f\"Data in graph: {data['x']}\")\n",
    "\n",
    "for key, item in data:\n",
    "    print(\"{} found in data\".format(key))\n",
    "    \n",
    "print(f\"Edge attribute in data: {'edge_attr' in data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Benchmark Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset, Planetoid\n",
    "\n",
    "enzymes_dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "cora_dataset = Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset: {enzymes_dataset.name} | size : {len(enzymes_dataset)} | # of classes: {enzymes_dataset.num_classes} | # of node features {enzymes_dataset.num_node_features}')\n",
    "print(f'Dataset: {cora_dataset.name} | size : {len(cora_dataset)} | # of classes: {cora_dataset.num_classes} | # of node features {cora_dataset.num_node_features}')\n",
    "\n",
    "# To shuffle dataset ~ equivalent to do randperm\n",
    "enzymes_dataset = enzymes_dataset.shuffle()\n",
    "cora_dataset = cora_dataset.shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "loader = DataLoader(enzymes_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for batch in loader:\n",
    "    print(batch)\n",
    "    print(batch.num_graphs)\n",
    "    break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1 style=\"text-align: center;\"> batch is a column vector which maps each node to its respective graph in the batch: </h1>\n",
    " <p style=\"text-align: center;\"> $\\mathrm{batch} = {\\begin{bmatrix} 0 & \\cdots & 0 & 1 & \\cdots & n - 2 & n -1 & \\cdots & n - 1 \\end{bmatrix}}^{\\top}$ </br>You can use it to, e.g., average node features in the node dimension for each graph individually:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_mean\n",
    "\n",
    "\n",
    "for data in loader:\n",
    "    print(f'Data: {data}')\n",
    "    print(f'# of graphs: {data.num_graphs}')\n",
    "    print(f'Size before average: {data.x.size()}')\n",
    "    x = scatter_mean(data.x, data.batch, dim=0)\n",
    "    print(f'Size after average: {x.size()}')\n",
    "    print(f'{\"=\"* 50}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transforms \n",
    "#### Letâ€™s look at an example, where we apply transforms on the ShapeNet dataset (containing 17,000 3D shape point clouds and per point labels from 16 shape categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(pos=[2518, 3], y=[2518])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.datasets import ShapeNet\n",
    "import open3d as o3d\n",
    "dataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'])\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this to visualize the first point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(dataset[0].pos.numpy())\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can convert the point cloud dataset into a graph dataset by generating nearest neighbor graphs from the point clouds via transforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://shapenet.cs.stanford.edu/iccv17/partseg/train_data.zip\n",
      "Extracting /tmp/ShapeNet/raw/train_data.zip\n",
      "Downloading https://shapenet.cs.stanford.edu/iccv17/partseg/train_label.zip\n",
      "Extracting /tmp/ShapeNet/raw/train_label.zip\n",
      "Downloading https://shapenet.cs.stanford.edu/iccv17/partseg/val_data.zip\n",
      "Extracting /tmp/ShapeNet/raw/val_data.zip\n",
      "Downloading https://shapenet.cs.stanford.edu/iccv17/partseg/val_label.zip\n",
      "Extracting /tmp/ShapeNet/raw/val_label.zip\n",
      "Downloading https://shapenet.cs.stanford.edu/iccv17/partseg/test_data.zip\n",
      "Extracting /tmp/ShapeNet/raw/test_data.zip\n",
      "Downloading https://shapenet.cs.stanford.edu/iccv17/partseg/test_label.zip\n",
      "Extracting /tmp/ShapeNet/raw/test_label.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "dataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'],\n",
    "                    pre_transform=T.KNNGraph(k=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We use the pre_transform to convert the data before saving it to disk (leading to faster loading times). Note that the next time the dataset is initialized it will already contain graph edges, even if you do not pass any transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapeNet(2349, categories=['Airplane']),\n",
       " Data(edge_index=[2, 15108], pos=[2518, 3], y=[2518]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(dataset[100].pos.numpy())\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
